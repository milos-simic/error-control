{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c86d6614",
   "metadata": {},
   "source": [
    "## Set up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d6ed38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T07:17:54.249457Z",
     "start_time": "2022-05-26T07:17:53.027976Z"
    }
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "import importlib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "from ectrl.control import split_the_data\n",
    "from ectrl.control import ClassificationTest, Umbrella, Typicality, DirectNP, TBC, EnsembleTBC\n",
    "from ectrl.control import ForcedInductiveConformal\n",
    "from ectrl.ratio import KernelDensityRatio\n",
    "from ectrl.augment import Interpolator\n",
    "from ectrl.evaluate import evaluate_once\n",
    "from ectrl.analyze import plot_3, analyze_numerically, select, style, plot_time\n",
    "import util\n",
    "import normeval\n",
    "\n",
    "from datetime import datetime\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38739e43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T07:17:54.253533Z",
     "start_time": "2022-05-26T07:17:54.250837Z"
    }
   },
   "outputs": [],
   "source": [
    "# Where to place the plots and the results\n",
    "res_dir = os.path.join('norm', 'results')\n",
    "\n",
    "# Make the directory if it doesn't exist\n",
    "pathlib.Path(res_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eef4a3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T07:17:54.347634Z",
     "start_time": "2022-05-26T07:17:54.255317Z"
    }
   },
   "outputs": [],
   "source": [
    "res_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71939ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_prefix = 'norm_'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc389e0b",
   "metadata": {},
   "source": [
    "## Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dca5d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T07:17:54.496245Z",
     "start_time": "2022-05-26T07:17:54.413298Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a function that generates datasets\n",
    "def generate_dataset(n_range, s_range, k_range, M, verbose=True, mean_range=[-100, 100],\n",
    "                    sigma_range=[0.1, 40]):\n",
    "    # Generate non-normal samples\n",
    "    nonnormal_samples = util.generate_pearson_nonnormal_samples(s_range, k_range, n_range,\n",
    "                                                                M, mean_range=mean_range,\n",
    "                                                               sigma_range=sigma_range)\n",
    "\n",
    "    # Calculate L, the number of normal samples of the same size\n",
    "    L = len(nonnormal_samples) // len(n_range)\n",
    "            \n",
    "    # Generate L normal samples of size n for each n in n_range\n",
    "    normal_samples = util.generate_normal_samples(n_range, L, mean_range=mean_range,\n",
    "                                                 sigma_range=sigma_range)\n",
    "\n",
    "    # Print how many samples were generated\n",
    "    if verbose:\n",
    "        print(\"Normal samples: \", len(normal_samples))\n",
    "        print(\"Non-normal samples: \", len(nonnormal_samples))\n",
    "\n",
    "    # Label the sets\n",
    "    y = [1 for sample in normal_samples] + [0 for sample in nonnormal_samples]\n",
    "\n",
    "    # Unify them\n",
    "    all_samples = normal_samples + nonnormal_samples\n",
    "    \n",
    "    return all_samples, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68d90ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075e2dc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T07:17:57.262652Z",
     "start_time": "2022-05-26T07:17:54.497476Z"
    }
   },
   "outputs": [],
   "source": [
    "s_range = [0]\n",
    "k_range = [1.02] + np.arange(1, 3, 0.125).tolist()[1:] + [2.98]\n",
    "mean_range = [-100, 100]\n",
    "sigma_range = [0.01, 40]\n",
    "n_range = [20]\n",
    "\n",
    "\n",
    "data, y = generate_dataset(n_range, s_range, k_range, 200)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82552b94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T07:17:57.277944Z",
     "start_time": "2022-05-26T07:17:57.264243Z"
    }
   },
   "outputs": [],
   "source": [
    "class DescriptorBuilder(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, n=20):\n",
    "        super(DescriptorBuilder, self).__init__()\n",
    "        self.features = [f'b{i}' for i in range(1, n - 1)]\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        # Not needed, but present for compatibility.\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        Z = np.sort(X)\n",
    "        \n",
    "        Z_min = np.min(Z, axis=1)[:, np.newaxis]\n",
    "        Z_max = np.max(Z, axis=1)[:, np.newaxis]\n",
    "        Z = -3 + 6 * (Z - Z_min) / (Z_max - Z_min)\n",
    "        \n",
    "        return pd.DataFrame(Z[:, 1:-1], columns=self.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9538871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d604526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c214fa8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T07:17:57.455357Z",
     "start_time": "2022-05-26T07:17:57.280724Z"
    }
   },
   "outputs": [],
   "source": [
    "descriptor_builder = DescriptorBuilder(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5172b9bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T07:18:02.517583Z",
     "start_time": "2022-05-26T07:17:57.457129Z"
    }
   },
   "outputs": [],
   "source": [
    "X = descriptor_builder.transform(data)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a626359",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T07:18:02.679083Z",
     "start_time": "2022-05-26T07:18:02.534332Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_preprocessor():\n",
    "    # Use the mean imputer and standard scaler for the numerical features.\n",
    " \n",
    "    preprocessor = Pipeline(steps=[('imputer', SimpleImputer(strategy = 'mean') ),\n",
    "                                     ('std_scaler', StandardScaler())\n",
    "                                    ])\n",
    "    \n",
    "    return preprocessor\n",
    "\n",
    "def create_classifier():\n",
    "    neural_net = MLPClassifier(solver='lbfgs', max_iter=500,\n",
    "                           activation='relu',\n",
    "                           alpha=0.01,\n",
    "                           hidden_layer_sizes=[9, 9],\n",
    "                           early_stopping=True, \n",
    "                           max_fun=13873,\n",
    "                           validation_fraction=0.2)\n",
    "    return neural_net\n",
    "\n",
    "def create_clf_pipeline():\n",
    "    preprocessor = create_preprocessor()\n",
    "    classifier = create_classifier()\n",
    "    \n",
    "    return Pipeline(steps=[('preprocessor', preprocessor), ('classifier', classifier)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe8ed2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T07:18:02.798732Z",
     "start_time": "2022-05-26T07:18:02.680474Z"
    }
   },
   "outputs": [],
   "source": [
    "target_class = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfde1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "(y == target_class).sum(), (y == 1 - target_class).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d6f2cd",
   "metadata": {},
   "source": [
    "## Create Controllers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855075a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "controllers = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c9c6c4",
   "metadata": {},
   "source": [
    "### SCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9446f0a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T06:58:53.601826Z",
     "start_time": "2022-05-26T06:58:53.591143Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a pipeline containing the preprocessor and classifier\n",
    "clf = create_clf_pipeline()\n",
    "\n",
    "# Define a function to extract the score\n",
    "def nn_statistic(nn_classifier, X):\n",
    "    X = nn_classifier['preprocessor'].transform(X)\n",
    "    return nn_classifier['classifier'].predict_proba(X)[:, target_class]\n",
    "\n",
    "nn_test = ClassificationTest(clf, nn_statistic,\n",
    "                              reserve=0.5,\n",
    "                              ci=None,\n",
    "                              augmentor=None, \n",
    "                              sample_size=None,\n",
    "                              target_class=target_class)\n",
    "controllers['SCT'] = nn_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd93ee8",
   "metadata": {},
   "source": [
    "### Umbrella"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217e70bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T14:49:47.134028Z",
     "start_time": "2022-05-18T14:49:47.130159Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add UA controllers\n",
    "for delta in [0.01, 0.05]:\n",
    "    for ensemble_size in [1, 5]:\n",
    "        base_clf = create_clf_pipeline()\n",
    "        ua = Umbrella(base_clf, nn_statistic, target_class=target_class,\n",
    "              delta=delta,\n",
    "              thresholds_size=0.5, # reserve 50% of target objects for classification\n",
    "              ensemble_size=ensemble_size\n",
    "             )\n",
    "        name = f'UA(delta={delta},m={ensemble_size})'\n",
    "        controllers[name] = ua"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d790108e",
   "metadata": {},
   "source": [
    "### TBC and WTBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5925744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add TBC and WTBC controllers\n",
    "for k in [3, 5, 7, 10]:\n",
    "    for test in ['mwu', 'ttest_ind']:\n",
    "        for distance in ['cityblock', 'cosine']:\n",
    "            for weights in ['none', 'reciprocal']:\n",
    "                tbc = TBC(k=k, test=test, distance=distance,\n",
    "                          weights=weights, target_class=target_class)\n",
    "                preprocessor = create_preprocessor()\n",
    "                if weights != 'none':\n",
    "                    method = 'WTBC'\n",
    "                    name = f'WTBC(k={k},test={test},distance={distance},weights={weights})'\n",
    "                else:\n",
    "                    method = 'TBC'\n",
    "                    name = f'TBC(k={k},test={test},distance={distance})'\n",
    "                \n",
    "                controllers[name] = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                                (method, tbc)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e0e31c",
   "metadata": {},
   "source": [
    "### CPF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391e4423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add CPF\n",
    "def nn_statistic_for_cpf(nn_classifier, X):\n",
    "    return nn_classifier.predict_proba(X)[:,target_class]\n",
    "\n",
    "for nonconformity in ['score', 'avgdev', 'nearest_neighbor']:\n",
    "    clf = create_classifier()\n",
    "    cpf = ForcedInductiveConformal(clf, nn_statistic_for_cpf,\n",
    "                               target_class=target_class, alpha=0.05,\n",
    "                               reserve=0.5, # use 50% as D_proper\n",
    "                                            # and the remaining 50% for calibration\n",
    "                               nonconformity=nonconformity,\n",
    "                               random_state=None)\n",
    "    cpf = Pipeline(steps=[ ('preprocessor', create_preprocessor()), ('CPF', cpf)])\n",
    "    name = f'CPF(nonconformity={nonconformity})'\n",
    "    controllers[name] = cpf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0092651d",
   "metadata": {},
   "source": [
    "### Typicality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4799f3d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T23:18:19.030316Z",
     "start_time": "2022-05-18T23:18:18.928606Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add Typicality Indices\n",
    "# Combine the preprocessor and the density estimator\n",
    "density_pipeline = Pipeline([\n",
    "    ('preprocessor', create_preprocessor()),\n",
    "    ('kde', KernelDensity()),\n",
    "])\n",
    "\n",
    "typicality = Typicality(density_pipeline, target_class=target_class)\n",
    "\n",
    "controllers['TI'] = typicality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c2a555",
   "metadata": {},
   "source": [
    "### Direct Neyman-Pearson Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9b5e3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T23:18:19.142297Z",
     "start_time": "2022-05-18T23:18:19.033093Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add DNP\n",
    "\n",
    "# instantiate a kernel density-ratio estimator\n",
    "kdr = KernelDensityRatio(kernel='polynomial',\n",
    "                         kernel_parameters={'degree' : 2})\n",
    "\n",
    "direct_np = DirectNP(kdr,\n",
    "                     target_class=target_class,\n",
    "                     threshold_subset_size=0.5) # 50% (use them to estimate the thresholds)\n",
    "\n",
    "dnp = Pipeline(steps=[('preprocessor', create_preprocessor()), ('DNP', direct_np)])\n",
    "controllers['DNP'] = dnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97be588",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(controllers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0200960a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-17T23:23:05.152928Z",
     "start_time": "2022-04-17T23:23:05.142165Z"
    }
   },
   "source": [
    "## Evaluate the Controllers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8373398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "seed = 11\n",
    "eval_size = 0.3\n",
    "nominal_rates =  np.arange(0.01, 1, 0.01)\n",
    "confidence_level = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b2d869",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T23:18:24.631280Z",
     "start_time": "2022-05-18T23:18:24.627726Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the experiment and evaluate all the controllers\n",
    "eval_results = evaluate_once(\n",
    "    controllers, \n",
    "    X, y, \n",
    "    target_class,\n",
    "    eval_size,\n",
    "    seed, \n",
    "    nominal_rates,\n",
    "    confidence_level=confidence_level\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81a95f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack the results\n",
    "df_results, df_clf_times, df_fit_times = eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce35ec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "filepath = os.path.join(res_dir, 'df_results.csv')\n",
    "df_results.to_csv(filepath, index=False)\n",
    "\n",
    "filepath = os.path.join(res_dir, 'df_fit_times.csv')\n",
    "df_fit_times.to_csv(filepath, index=False)\n",
    "\n",
    "filepath = os.path.join(res_dir, 'df_clf_times.csv')\n",
    "df_clf_times.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338cfecd",
   "metadata": {},
   "source": [
    "## Analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea3568a",
   "metadata": {},
   "source": [
    "### Load the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb58c75c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T23:08:39.389173Z",
     "start_time": "2022-05-18T23:08:39.375642Z"
    }
   },
   "outputs": [],
   "source": [
    "filepath = os.path.join(res_dir, 'df_results.csv')\n",
    "df_results = pd.read_csv(filepath)\n",
    "\n",
    "filepath = os.path.join(res_dir, 'df_fit_times.csv')\n",
    "df_fit_times = pd.read_csv(filepath)\n",
    "\n",
    "filepath = os.path.join(res_dir, 'df_clf_times.csv')\n",
    "df_clf_times = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b772ca69",
   "metadata": {},
   "source": [
    "### Choose the Best UA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8f78d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "choices = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021f9c90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T18:33:18.198256Z",
     "start_time": "2022-05-18T18:33:18.180772Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_3(\n",
    "    df_results[df_results['method'] == 'UA'],\n",
    "    'nominal',\n",
    "    'target_estimate', \n",
    "    'delta',\n",
    "    ribbon=('target_lower', 'target_upper'),\n",
    "    ab = (1, 0), \n",
    "    display_plot=False,\n",
    "    save_plot=True, location=res_dir, prefix=set_prefix + 'UA',\n",
    "    width=7, height=5,\n",
    "    facet_parameter='ensemble_size'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2df090",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3(\n",
    "    df_results[df_results['method'] == 'UA'],\n",
    "    'target_estimate',\n",
    "    'nontarget_estimate', \n",
    "    'delta',\n",
    "    ribbon=('nontarget_lower', 'nontarget_upper'), \n",
    "    display_plot=False,\n",
    "    save_plot=True, location=res_dir, prefix=set_prefix + 'UA',\n",
    "    width=7, height=5,\n",
    "    facet_parameter='ensemble_size'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401568d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = analyze_numerically(df_results, ['delta', 'ensemble_size'], 'UA')\n",
    "r.sort_values('D(A, OA)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f0efe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.sort_values('D(A, B, OA)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa266cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "choices['UA'] = {\n",
    "    'exact' : {\n",
    "        'ensemble_size' : 5,\n",
    "        'delta' : 0.05\n",
    "    },\n",
    "    'valid' : {\n",
    "        'ensemble_size' : 5,\n",
    "        'delta' : 0.05\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d205f0",
   "metadata": {},
   "source": [
    "### Choose the Best TBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d743adec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9facf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3(\n",
    "    df_results[df_results['method'] == 'TBC'],\n",
    "    'nominal',\n",
    "    'target_estimate', \n",
    "    'k',\n",
    "    ribbon=('target_lower', 'target_upper'),\n",
    "    ab = (1, 0), \n",
    "    display_plot=False,\n",
    "    save_plot=True, location=res_dir, prefix=set_prefix + 'TBC',\n",
    "    width=7, height=5,\n",
    "    facet_parameter='test+distance'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271b3fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3(\n",
    "    df_results[df_results['method'] == 'TBC'],\n",
    "    'target_estimate',\n",
    "    'nontarget_estimate',\n",
    "    'k',\n",
    "    ribbon=('nontarget_lower', 'nontarget_upper'),\n",
    "    display_plot=False,\n",
    "    save_plot=True, location=res_dir, prefix=set_prefix + 'TBC',\n",
    "    width=7, height=5,\n",
    "    facet_parameter='test+distance'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28573a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3(\n",
    "    df_results[df_results['method'] == 'TBC'],\n",
    "    'nominal',\n",
    "    'nontarget_estimate',\n",
    "    'k',\n",
    "    ribbon=('nontarget_lower', 'nontarget_upper'),\n",
    "    display_plot=False,\n",
    "    save_plot=True, location=res_dir, prefix=set_prefix + 'TBC',\n",
    "    width=7, height=5,\n",
    "    facet_parameter='test+distance'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f95d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = analyze_numerically(df_results, ['k', 'test', 'distance'], 'TBC')\n",
    "r.sort_values('D(A, B, OA)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e6a239",
   "metadata": {},
   "outputs": [],
   "source": [
    "choices['TBC'] = {\n",
    "    'valid' : {\n",
    "        'k' : 3,\n",
    "        'test' : 'ttest_ind',\n",
    "        'distance' : 'cityblock'\n",
    "    },\n",
    "    'exact' : {\n",
    "        'k' : 3,\n",
    "        'test' : 'ttest_ind',\n",
    "        'distance' : 'cityblock'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f285f5c",
   "metadata": {},
   "source": [
    "### Choose the Best WTBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f83473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import ectrl.analyze\n",
    "importlib.reload(ectrl.analyze)\n",
    "from ectrl.analyze import plot_3\n",
    "plot_3(\n",
    "    df_results[df_results['method'] == 'WTBC'],\n",
    "    'nominal',\n",
    "    'target_estimate', \n",
    "    'k',\n",
    "    ribbon=('target_lower', 'target_upper'),\n",
    "    ab = (1, 0), \n",
    "    display_plot=False,\n",
    "    save_plot=True, location=res_dir, prefix=set_prefix + 'WTBC',\n",
    "    width=7, height=5,\n",
    "    #x_lim=(0, 0.1), y_lim=(0, 0.1),\n",
    "    facet_parameter='test+distance'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072e2096",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3(\n",
    "    df_results[df_results['method'] == 'WTBC'],\n",
    "    'target_estimate',\n",
    "    'nontarget_estimate',\n",
    "    'k',\n",
    "    #ribbon=('nontarget_lower', 'nontarget_upper'),\n",
    "    display_plot=False,\n",
    "    save_plot=True, location=res_dir, prefix=set_prefix + 'WTBC',\n",
    "    width=7, height=5,\n",
    "    facet_parameter='test+distance'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98007654",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3(\n",
    "    df_results[df_results['method'] == 'WTBC'],\n",
    "    'nominal',\n",
    "    'nontarget_estimate',\n",
    "    'k',\n",
    "    #ribbon=('nontarget_lower', 'nontarget_upper'),\n",
    "    display_plot=False,\n",
    "    save_plot=True, location=res_dir, prefix=set_prefix + 'WTBC',\n",
    "    width=7, height=5,\n",
    "    facet_parameter='test+distance'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ba6c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = analyze_numerically(df_results, ['k', 'test', 'distance'], 'WTBC')\n",
    "r.sort_values('D(A, B, OA)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f599a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "choices['WTBC'] = {\n",
    "    'valid' : {\n",
    "        'k' : 3,\n",
    "        'test' : 'ttest_ind',\n",
    "        'distance' : 'cityblock'\n",
    "    },\n",
    "    'exact' : {\n",
    "        'k' : 3,\n",
    "        'test' : 'ttest_ind',\n",
    "        'distance' : 'cosine' \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca10594c",
   "metadata": {},
   "source": [
    "### Choose the Best CPF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c674f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3(\n",
    "    df_results[df_results['method'] == 'CPF'],\n",
    "    'nominal',\n",
    "    'target_estimate', \n",
    "    'nonconformity',\n",
    "    ribbon=('target_lower', 'target_upper'),\n",
    "    ab = (1, 0), \n",
    "    display_plot=False,\n",
    "    save_plot=True, location=res_dir, prefix=set_prefix + 'CPF',\n",
    "    width=7, height=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eb659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3(\n",
    "    df_results[df_results['method'] == 'CPF'],\n",
    "    'target_estimate',\n",
    "    'nontarget_estimate',\n",
    "    'nonconformity',\n",
    "    ribbon=('nontarget_lower', 'nontarget_upper'),\n",
    "    display_plot=False,\n",
    "    save_plot=True, location=res_dir, prefix=set_prefix + 'WTBC',\n",
    "    width=7, height=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964028ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = analyze_numerically(df_results, ['nonconformity'], 'CPF')\n",
    "r.sort_values('D(A, B, OA)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4c04ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "choices['CPF'] = {\n",
    "    'exact' :{\n",
    "        'nonconformity' : 'avgdev'\n",
    "    },\n",
    "    'valid' :{\n",
    "        'nonconformity' : 'avgdev'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b31afdb",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a87e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "choices['SCT'] = {'exact' : {}, 'valid' : {}}\n",
    "choices['TI'] = {'exact' : {}, 'valid' : {}}\n",
    "choices['DNP'] = {'exact' : {}, 'valid' : {}}\n",
    "\n",
    "pp.pprint(choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cdd665",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dfs = {}\n",
    "clf_times_dfs = {}\n",
    "fit_times_dfs = {}\n",
    "\n",
    "for focus in ['exact', 'valid']:\n",
    "    focus_choices = {method : choices[method][focus] for method in choices}\n",
    "    results_dfs[focus] = select(df_results, focus_choices)\n",
    "    clf_times_dfs[focus] = select(df_clf_times, focus_choices)\n",
    "    fit_times_dfs[focus] = select(df_fit_times, focus_choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5c21b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = os.path.join(res_dir, f'{set_prefix}choices.p')\n",
    "pickle.dump(choices, open(f, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46243522",
   "metadata": {},
   "source": [
    "### Analyze Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d21e4a",
   "metadata": {},
   "source": [
    "#### Average Classification Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6146e1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T22:49:47.439229Z",
     "start_time": "2022-05-18T22:49:47.417872Z"
    }
   },
   "outputs": [],
   "source": [
    "for focus in clf_times_dfs:\n",
    "    print(focus)\n",
    "    display(clf_times_dfs[focus][['method', 'time']].sort_values('time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeed0e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "for focus in clf_times_dfs:\n",
    "    plot_time(clf_times_dfs[focus], 'method', 'time', 'method',\n",
    "         location=res_dir, name=set_prefix + f'{focus}_average_classification_time.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b603cf5d",
   "metadata": {},
   "source": [
    "#### Fit Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f986738",
   "metadata": {},
   "outputs": [],
   "source": [
    "for focus in fit_times_dfs:\n",
    "    print(focus)\n",
    "    display(fit_times_dfs[focus][['method', 'time']].sort_values('time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb86f352",
   "metadata": {},
   "outputs": [],
   "source": [
    "for focus in fit_times_dfs:\n",
    "    plot_time(fit_times_dfs[focus], 'method', 'time', 'method',\n",
    "         location=res_dir, name=set_prefix + f'{focus}_fit_times.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b39480",
   "metadata": {},
   "source": [
    "### Check the Rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c22556f",
   "metadata": {},
   "source": [
    "#### Nominal vs. Target Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea490eed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for focus in results_dfs:\n",
    "    print(focus)\n",
    "    g = plot_3(\n",
    "        results_dfs[focus],\n",
    "        'nominal',\n",
    "        'target_estimate',\n",
    "        'method',\n",
    "        ribbon=('target_lower', 'target_upper'),\n",
    "        ab=(1, 0),\n",
    "        legend_position=(0.35, 0.8), legend_name='', legend_ncol=2,\n",
    "        legend_text_size=15, legend_key_width=35,\n",
    "        display_plot=True,\n",
    "        save_plot=True, location=res_dir, width=5.35, height=4.35,\n",
    "        prefix= set_prefix + f'_{focus}_'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4aec91",
   "metadata": {},
   "source": [
    "#### Target vs. Other (Estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f486b5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for focus in results_dfs:\n",
    "    print(focus)\n",
    "    plot_3(\n",
    "        results_dfs[focus],\n",
    "        'target_estimate',\n",
    "        'nontarget_estimate',\n",
    "        'method',\n",
    "        ribbon=('nontarget_lower', 'nontarget_upper'),\n",
    "        save_plot=True, location=res_dir, width=5, height=4,\n",
    "        prefix=set_prefix + f'_{focus}_'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca414b2",
   "metadata": {},
   "source": [
    "#### Nominal vs. Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128f5525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ectrl.analyze\n",
    "importlib.reload(ectrl.analyze)\n",
    "from ectrl.analyze import style, plot_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece0e2be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T18:29:50.350721Z",
     "start_time": "2022-05-18T18:29:50.246198Z"
    }
   },
   "outputs": [],
   "source": [
    "for focus in results_dfs:\n",
    "    print(focus)\n",
    "    g = plot_3(\n",
    "        results_dfs[focus],\n",
    "        'nominal',\n",
    "        'nontarget_estimate',\n",
    "        'method',\n",
    "        ribbon=('nontarget_lower', 'nontarget_upper'),\n",
    "        legend_position=(0.5, 0.9), legend_name='', legend_ncol=4, legend_title=False,\n",
    "        legend_text_size=13, legend_key_width=35, legend_key_height=10,\n",
    "        display_plot=True,\n",
    "        save_plot=True, location=res_dir, width=5.35, height=4.35,\n",
    "        prefix= set_prefix + f'_{focus}_'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219fe9e4",
   "metadata": {},
   "source": [
    "#### Nominal vs. Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fff9c0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T16:00:21.734047Z",
     "start_time": "2022-05-18T16:00:21.731293Z"
    }
   },
   "outputs": [],
   "source": [
    "for focus in results_dfs:\n",
    "    print(focus)\n",
    "    plot_3(\n",
    "        results_dfs[focus],\n",
    "        'nominal',\n",
    "        'accuracy_estimate',\n",
    "        'method',\n",
    "        ribbon=('accuracy_lower', 'accuracy_upper'),\n",
    "        save_plot=True, location=res_dir, width=5, height=4,\n",
    "        prefix=set_prefix + f'_{focus}_'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded842ff",
   "metadata": {},
   "source": [
    "#### Target Estimate vs. Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cac776",
   "metadata": {},
   "outputs": [],
   "source": [
    "for focus in results_dfs:\n",
    "    print(focus)\n",
    "    plot_3(\n",
    "        df_results,\n",
    "        'target_estimate',\n",
    "        'accuracy_estimate',\n",
    "        'method',\n",
    "        #ribbon=('accuracy_lower', 'accuracy_upper'),\n",
    "        save_plot=True, location=res_dir, width=5, height=4,\n",
    "        prefix=set_prefix + f'_{focus}_'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b460bd23",
   "metadata": {},
   "source": [
    "## Compare With Normality Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad79ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_preprocessor11():\n",
    "    # Use the mean imputer and standard scaler for the numerical features.\n",
    " \n",
    "    preprocessor = Pipeline(steps=[('imputer', SimpleImputer(strategy = 'mean') ),\n",
    "                                     ('std_scaler', StandardScaler())\n",
    "                                    ])\n",
    "    \n",
    "    return preprocessor\n",
    "\n",
    "def create_classifier11():\n",
    "    neural_net = MLPClassifier(solver='lbfgs', max_iter=500,\n",
    "                           activation='relu',\n",
    "                           alpha=0.01,\n",
    "                           hidden_layer_sizes=[10],\n",
    "                           early_stopping=True, \n",
    "                           max_fun=13873,\n",
    "                           validation_fraction=0.2)\n",
    "    return neural_net\n",
    "\n",
    "def create_clf_pipeline11():\n",
    "    preprocessor = create_preprocessor11()\n",
    "    classifier = create_classifier11()\n",
    "    \n",
    "    return Pipeline(steps=[('preprocessor', preprocessor), ('classifier', classifier)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e27c887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a082c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f082a394",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.01, 0.05]\n",
    "\n",
    "test_names = ['SW', 'LF', 'AD', 'DP', 'JB', 'SF', 'CVM']\n",
    "\n",
    "tests = {\n",
    "    alpha : {} for alpha in alphas\n",
    "}\n",
    "\n",
    "for test_name in test_names:\n",
    "    test_function, test_statistic = util.get_test(test_name)\n",
    "    for alpha in alphas:\n",
    "        test = util.TestClassifier(test_function, test_statistic, alpha)\n",
    "        tests[alpha][test_name] = test\n",
    "\n",
    "class KurtosisTest(object):\n",
    "    def __init__(self, alpha, alternative):\n",
    "        self.alpha = alpha\n",
    "        self.alternative = alternative\n",
    "\n",
    "    def predict(self, X):\n",
    "        return st.kurtosistest(X, axis=1, alternative=self.alternative).pvalue >= self.alpha\n",
    "\n",
    "for alpha in alphas:\n",
    "    tests[alpha]['KT'] = KurtosisTest(alpha, 'less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5635fa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline containing the preprocessor and classifier\n",
    "clf = create_clf_pipeline11()\n",
    "\n",
    "# Define a function to extract the score\n",
    "def nn_statistic(nn_classifier, X):\n",
    "    X = nn_classifier['preprocessor'].transform(X)\n",
    "    return nn_classifier['classifier'].predict_proba(X)[:, target_class]\n",
    "\n",
    "for alpha in alphas:\n",
    "    nn_test = ClassificationTest(clf, nn_statistic,\n",
    "                              reserve=0.5,\n",
    "                              ci=None,\n",
    "                              alpha=alpha,\n",
    "                              augmentor=None, \n",
    "                              sample_size=None,\n",
    "                              target_class=target_class)\n",
    "    tests[alpha]['SCT'] = nn_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1119dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 0.2\n",
    "data, y = generate_dataset([20], s_range, k_range, 400, mean_range=mean_range,\n",
    "                           sigma_range=sigma_range)\n",
    "y = np.array(y)\n",
    "descriptor_builder = DescriptorBuilder(q=q)\n",
    "X = descriptor_builder.transform(data)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9996c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for alpha in alphas:\n",
    "    print('Fitting ', alpha)\n",
    "    tests[alpha]['SCT'].fit(X, y)\n",
    "    print('\\t', tests[alpha]['SCT'].classifier['classifier'].loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b462e88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for alpha in alphas:\n",
    "#    print(tests[alpha]['SCT'].classifier['classifier'].loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfc0225",
   "metadata": {},
   "source": [
    "#### Evaluate on symmetric platykurtic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1ce4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 10000\n",
    "G_data = normeval.generate_G_data(n_range=[20], L=L, groups={4 : normeval.groups[4]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a37b7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b8a2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for alpha in tests:\n",
    "    print(alpha)\n",
    "    for code in tests[alpha]:\n",
    "        print('\\t', code)\n",
    "        test = tests[alpha][code]\n",
    "        if code == 'SCT':\n",
    "            df = normeval.evaluate_power(test,\n",
    "                                         {key : descriptor_builder.transform(G_data[key]) for key in G_data})\n",
    "        else:\n",
    "            df = normeval.evaluate_power(test, G_data)\n",
    "        df['alpha'] = alpha\n",
    "        df['test'] = code\n",
    "        dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f5486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_pow_df = pd.concat(dfs)\n",
    "res_pow_df = res_pow_df.reset_index(drop=True)\n",
    "res_pow_df = res_pow_df.rename({4 : 'power'}, axis=1)\n",
    "res_pow_df['alpha'] = res_pow_df['alpha'].astype(str)\n",
    "res_pow_df['power'] = res_pow_df['power'].astype(float)\n",
    "lower, upper = proportion_confint(res_pow_df['power'] * L, L, alpha=0.01, method='beta')\n",
    "res_pow_df['lower'] = lower\n",
    "res_pow_df['upper'] = upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f258ada6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for alpha in alphas:\n",
    "    mask = (res_pow_df['alpha'] == str(alpha)) & (~res_pow_df['test'].isin(['JB', 'SF']))\n",
    "    g = ggplot(res_pow_df[mask], aes(x='test', y='power', color='test', fill='test')) +\\\n",
    "        geom_bar(stat='identity', alpha=0.4, size=1, show_legend=False) +\\\n",
    "        geom_errorbar(aes(ymin='lower', ymax='upper'), size=2, show_legend=False) +\\\n",
    "        scale_color_brewer(type='qual', palette=2) +\\\n",
    "        scale_fill_brewer(type='qual', palette=2) +\\\n",
    "        labs(x = '', y='Power') +\\\n",
    "        theme_classic() +\\\n",
    "        theme(legend_position='none', text=element_text(size=18))\n",
    "    \n",
    "    display(g)\n",
    "    filename = os.path.join(res_dir, f'norm_test_power_G4_20_{alpha}.jpg')\n",
    "    print(filename)\n",
    "    g.save(filename, dpi=500, width=5, height=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c428cd7",
   "metadata": {},
   "source": [
    "#### Evaluate on New SP Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d601008",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_k_range = np.array(k_range[:-1]) + np.diff(k_range) / 2\n",
    "print(new_k_range)\n",
    "new_k_range = [float(k) for k in new_k_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78cf52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 10000\n",
    "nonnormal_data = {k : None for k in new_k_range}\n",
    "\n",
    "for k in new_k_range:\n",
    "    print(k)\n",
    "    nonnormal_data[k] = util.generate_pearson_nonnormal_samples([0], [k], [20], L,\n",
    "                                                         mean_range=mean_range,\n",
    "                                                        sigma_range=sigma_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484576f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_results = []\n",
    "for alpha in tests:\n",
    "    for code in tests[alpha]:\n",
    "        print(code, alpha)\n",
    "        for k in nonnormal_data:\n",
    "            if code == 'SCT':\n",
    "                sp_samples = descriptor_builder.transform(nonnormal_data[k])\n",
    "            else:\n",
    "                sp_samples = nonnormal_data[k]\n",
    "            y_sp_pred = tests[alpha][code].predict(sp_samples)\n",
    "            power = (np.array(y_sp_pred) == 0).mean()\n",
    "            sp_results.append([k, alpha, code, power])\n",
    "            print('\\t', k, power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d87a75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_pow_df = pd.DataFrame(sp_results, columns=['k', 'alpha', 'test', 'power'])\n",
    "#sp_pow_df = res_pow_df.reset_index(drop=True)\n",
    "#res_pow_df = res_pow_df.rename({4 : 'power'}, axis=1)\n",
    "sp_pow_df['alpha'] = sp_pow_df['alpha'].astype(str)\n",
    "sp_pow_df['power'] = sp_pow_df['power'].astype(float)\n",
    "lower, upper = proportion_confint(sp_pow_df['power'] * L, L, alpha=0.01, method='beta')\n",
    "sp_pow_df['lower'] = lower\n",
    "sp_pow_df['upper'] = upper\n",
    "sp_pow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1950f2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_spec = guide_legend(ncol=2)\n",
    "for alpha in alphas:\n",
    "    mask = (sp_pow_df['alpha'] == str(alpha)) & ~sp_pow_df['test'].isin(['JB', 'SF'])\n",
    "    g = ggplot(sp_pow_df[mask], aes(x='k', y='power', \n",
    "                                    shape='test', color='test')) +\\\n",
    "        geom_line(aes(group='test'), size=1.3, linetype='dotted') +\\\n",
    "        geom_point(size=4) +\\\n",
    "        scale_color_brewer(type='qual', palette=2) +\\\n",
    "        scale_fill_brewer(type='qual', palette=2) +\\\n",
    "        labs(x = 'Kurtosis', y='Power') +\\\n",
    "        theme_classic() +\\\n",
    "        theme(legend_title=element_blank(), legend_position=(0.65, 0.7),\n",
    "             legend_key_width=30, legend_box_margin=0) +\\\n",
    "        guides(color=legend_spec)\n",
    "    \n",
    "    display(g)\n",
    "    filename = os.path.join(res_dir, f'norm_test_power_sp_20_{alpha}.jpg')\n",
    "    print(filename)\n",
    "    g.save(filename, dpi=500, width=5, height=4)\n",
    "#geom_errorbar(aes(ymin='lower', ymax='upper'), size=2, show_legend=False) +\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ce472c",
   "metadata": {},
   "source": [
    "## Nondeterministic Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3753dfce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683da29e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02803774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45aa5b80",
   "metadata": {},
   "source": [
    "## Nondeterministic Test (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c92a099",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T07:53:01.515603Z",
     "start_time": "2022-05-26T07:53:01.512562Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make a pipeline containing the preprocessor and classifier\n",
    "clf = create_clf_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd439476",
   "metadata": {},
   "source": [
    "### Evaluation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46084e40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T07:53:01.663718Z",
     "start_time": "2022-05-26T07:53:01.517567Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "import math\n",
    "\n",
    "res_dir = os.path.join(res_dir, 'nondet')\n",
    "pathlib.Path(res_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8672094a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T07:53:01.756435Z",
     "start_time": "2022-05-26T07:53:01.666856Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(target, nominal, epsilon, runs, m, n, X, y, seeds, clf):\n",
    "    support = 0\n",
    "    estimates = []\n",
    "    lower_estimates = []\n",
    "    upper_estimates = []\n",
    "    errors = []\n",
    "\n",
    "    error = 0\n",
    "    lower_bound = (1 - nominal) / n\n",
    "    upper_bound = (epsilon * (n + 1) - nominal) / n\n",
    "\n",
    "    for k in range(runs):\n",
    "        if k % 10 == 9:\n",
    "            print(k + 1, datetime.now().strftime('%H:%M:%S'), end='\\r', flush=True)\n",
    "        rng = np.random.default_rng(seeds[k])\n",
    "        X_cv, X_eval, y_cv, y_eval = train_test_split(X, y, \n",
    "                                                  test_size=0.3, \n",
    "                                                  stratify = y.tolist(),\n",
    "                                                 random_state=seeds[k])\n",
    "    \n",
    "        clf.set_params(**{'classifier__random_state' : seeds[k]})\n",
    "        clf = clf.fit(X_cv, y_cv)\n",
    "    \n",
    "        Z = X_eval.loc[y_eval == target, :].reset_index(drop=True)\n",
    "        scores = clf.predict_proba(Z)[:, target_class]\n",
    "    \n",
    "        false = 0\n",
    "        for j in range(m):\n",
    "            sample = rng.choice(scores, n + 1, replace=False)\n",
    "            score = sample[0] \n",
    "            sample = np.sort(sample[1:])\n",
    "        \n",
    "            if target == 1:\n",
    "                more_extreme = np.searchsorted(sample, score, 'right')\n",
    "            else:\n",
    "                i = np.searchsorted(sample, score, 'left')\n",
    "                more_extreme = n - i + 1\n",
    "        \n",
    "            p_value = more_extreme / n\n",
    "        \n",
    "            if epsilon > 0:\n",
    "                correction = rng.uniform(lower_bound, upper_bound)\n",
    "                if p_value + correction <= nominal:\n",
    "                    false = false + 1\n",
    "            else:\n",
    "                #r = st.norm.ppf(1 - 0.01 / 2) / (4*len(scores))\n",
    "                if p_value <= (nominal * (n + 1) - 1) / n:\n",
    "                    false = false + 1\n",
    "    \n",
    "        lower, upper = proportion_confint(false, m, 0.01, 'jeffreys')\n",
    "\n",
    "        estimate = false / m\n",
    "        estimates.append(estimate)\n",
    "    \n",
    "        lower_estimates.append(lower)\n",
    "        upper_estimates.append(upper)\n",
    "    \n",
    "        if nominal < estimate:\n",
    "            error = error + (estimate - nominal)\n",
    "        elif estimate < nominal - epsilon:\n",
    "            error = error + (nominal - epsilon - estimate)\n",
    "            \n",
    "    return (lower_estimates, estimates, upper_estimates, error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35baf985",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T13:48:47.843350Z",
     "start_time": "2022-05-12T13:48:47.836262Z"
    }
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "errors = []\n",
    "supports = []\n",
    "\n",
    "settings = [\n",
    "    (0.05, 20, 0), (0.05, 50, 0), (0.05, 50, 0.02), (0.05, 100, 0.01)\n",
    "]\n",
    "\n",
    "for alpha, n, epsilon in settings:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2718a062",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T08:03:14.424918Z",
     "start_time": "2022-05-26T07:53:01.761296Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "runs = 100\n",
    "target = 1\n",
    "seeds = [11*k + 19 for k in range(runs)]\n",
    "m = 10000\n",
    "\n",
    "results = {}\n",
    "errors = []\n",
    "supports = []\n",
    "\n",
    "settings = [\n",
    "    (0.05, 20, 0), (0.05, 50, 0), (0.05, 50, 0.02), (0.05, 100, 0.01)\n",
    "]\n",
    "\n",
    "for nominal, n, epsilon in settings: \n",
    "    if nominal <= epsilon or (epsilon > 0 and epsilon < 1 / (n + 1)):\n",
    "        continue\n",
    "    print(nominal, n, epsilon, '\\n')\n",
    "\n",
    "    results[(nominal, epsilon, n)] = {}\n",
    "\n",
    "    lower, estimates, upper, error = evaluate(target, nominal, epsilon,\n",
    "                                                 runs, m, n, X, y, seeds, clf)\n",
    "        \n",
    "    results[(nominal, epsilon, n)]['df'] = pd.DataFrame(\n",
    "                {'lower':lower, 'estimates': estimates, 'upper':upper}\n",
    "            )\n",
    "    errors.append([nominal, n, error/runs])\n",
    "        \n",
    "    support = 0\n",
    "    for i in range(runs):\n",
    "        if nominal - epsilon <= estimates[i] <= nominal:\n",
    "            support = support + 1\n",
    "\n",
    "    e = support / runs\n",
    "    l, u = proportion_confint(support, runs, 0.01, 'jeffreys')\n",
    "    supports.append([nominal, n, l, e, u])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328b9944",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T08:03:14.453338Z",
     "start_time": "2022-05-26T08:03:14.426569Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(results, open(os.path.join(res_dir, 'interval_df.p'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07794b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T08:03:14.561114Z",
     "start_time": "2022-05-26T08:03:14.454801Z"
    }
   },
   "outputs": [],
   "source": [
    "res_nd = pickle.load(open(os.path.join(res_dir, 'interval_df.p'), 'rb'))\n",
    "res_nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa655119",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T08:03:14.634921Z",
     "start_time": "2022-05-26T08:03:14.564950Z"
    }
   },
   "outputs": [],
   "source": [
    "errors # average errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a67f84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T08:03:15.649899Z",
     "start_time": "2022-05-26T08:03:14.639962Z"
    }
   },
   "outputs": [],
   "source": [
    "#epsilon = 0.02\n",
    "for key in res_nd:\n",
    "    alpha, epsilon, n = key\n",
    "    print(key)\n",
    " \n",
    "    df = res_nd[key]['df']\n",
    "    runs = df.shape[0]\n",
    "    fig = plt.figure(figsize=(4, 2), dpi=500)\n",
    "    plt.rc('font', size=10) \n",
    "    x = list(range(runs))\n",
    "    #plt.fill_between(x, df['lower'], df['upper'], color='red', alpha=0.2)\n",
    "    #plt.plot(x, df['estimates'], color='blue', linestyle='--', linewidth=0.5) #\n",
    "    plt.scatter(x, df['estimates'], marker='x', color='blue', s=2)\n",
    "    plt.plot((x, x), (df['lower'], df['upper']), color='blue',\n",
    "             linestyle='--', linewidth=0.5)\n",
    "\n",
    "    plt.plot(x, np.repeat(alpha, runs), color='black', linewidth=1.5)\n",
    "    if epsilon > 0:\n",
    "        plt.plot(x, np.repeat(alpha - epsilon, runs), color='black', linewidth=1.5)\n",
    "    \n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('')\n",
    "    plt.xticks([])\n",
    "\n",
    "    filename = os.path.join(res_dir, f'interval_norm_{alpha}_{epsilon}_{n}.jpg')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=500, figsize=(4, 2), bbox_inches='tight')\n",
    "    #plt.title(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdb2f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = create_clf_pipeline()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6feb1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf['classifier'].loss_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec6f35c",
   "metadata": {},
   "source": [
    "### Evaluation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46206fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndt_res_dir = os.path.join('norm', 'results', 'ndt_v2')\n",
    "pathlib.Path(ndt_res_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc990e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DescriptorBuilder1(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, q=0.1):\n",
    "        super(DescriptorBuilder1, self).__init__()\n",
    "        self.q = q\n",
    "        # Set the names of the features in the descriptors\n",
    "        self.features = ['n', 'mad', 'skewness', 'kurtosis',\n",
    "                         'left_mean', 'right_mean', 'kt']\n",
    "        \n",
    "        if self.q is not None:\n",
    "            qs = [round(j * q, 8) for j in range(1, int(1 / q) + 1)]\n",
    "            if qs[-1] == 1:\n",
    "                qs = qs[:-1]\n",
    "            self.qs = qs\n",
    "        \n",
    "            self.features += ['q{:.2f}'.format(q) for q in self.qs]\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        # Not needed, but present for compatibility.\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # Note: Currently works only on a list of lists or a single list.\n",
    "        if isinstance(X, list):\n",
    "            if all(isinstance(x, list) for x in X):\n",
    "                X = [self.get_descriptor(x) for x in X]\n",
    "                return pd.DataFrame(X, columns=self.features)\n",
    "            else:\n",
    "                X = self.get_descriptor(X)\n",
    "                return X\n",
    "        else:\n",
    "            # Pandas dataframes and numpy arrays are not supported for now.\n",
    "            pass\n",
    "        \n",
    "    def get_descriptor(self, sample, sort=True, eps=1e-8):\n",
    "        if sort:\n",
    "            sample.sort()\n",
    "        \n",
    "        # Calculate the DP test's p-value\n",
    "        dpp = st.normaltest(sample)[1]\n",
    "        \n",
    "        # Scale the sample to [-3, 3]\n",
    "        maximum = max(sample)\n",
    "        minimum = min(sample)\n",
    "        sample = [-3 + 6 * (x - minimum) / (maximum - minimum) for x in sample]\n",
    "        \n",
    "        # Calculate selected descriptive statistics\n",
    "        maximum = max(sample)\n",
    "        minimum = min(sample)\n",
    "        n = len(sample)\n",
    "        mean = np.mean(sample)\n",
    "        median = np.median(sample)\n",
    "        sd = np.std(sample)\n",
    "        kurtosis = st.kurtosis(sample, fisher=False, bias=False)\n",
    "        skewness = st.skew(sample)\n",
    "        mad = st.median_abs_deviation(sample)\n",
    "        \n",
    "        # Calculate the means of the left and right tails\n",
    "        coeff = 0.2 # 0.1\n",
    "        left_limit = int(np.floor(coeff * n))\n",
    "        left_tail = sample[:left_limit]\n",
    "        left_mean = np.mean(left_tail)\n",
    "\n",
    "        coeff = 0.2\n",
    "        right_limit = int(np.ceil(n - coeff * n))\n",
    "        right_tail = sample[right_limit:]\n",
    "        right_mean = np.mean(right_tail)\n",
    "        \n",
    "        \n",
    "        # Create the descriptor\n",
    "        descriptor = [n, mad, skewness, kurtosis,\n",
    "                      left_mean, right_mean, dpp] \n",
    "\n",
    "            \n",
    "        # Include the quantiles to the descriptor if q is specified\n",
    "        if self.q is not None:\n",
    "            quantiles = np.quantile(sample, self.qs)#.tolist()\n",
    "            quantiles = quantiles.tolist()\n",
    "            descriptor.extend(quantiles)\n",
    "        \n",
    "        return descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67793c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clf(q=0.2):\n",
    "    # Use the mean imputer and standard scaler for the numerical features.\n",
    "    descriptor_builder = DescriptorBuilder1(q=q)\n",
    " \n",
    "    preprocessor = Pipeline(steps=[('imputer', SimpleImputer(strategy = 'mean') ),\n",
    "                                     ('std_scaler', StandardScaler())\n",
    "                                    ])\n",
    "    \n",
    "    neural_net = MLPClassifier(solver='lbfgs', max_iter=100,\n",
    "                           activation='relu',\n",
    "                           alpha=0.01,\n",
    "                           hidden_layer_sizes=[9, 9],\n",
    "                           early_stopping=True, \n",
    "                           max_fun=13873,\n",
    "                           validation_fraction=0.2)\n",
    "    \n",
    "    return Pipeline(steps=[\n",
    "        ('descriptor_builder', descriptor_builder),\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', neural_net)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febcb53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_range = [0]\n",
    "k_range = [1.02] + np.arange(1, 3, 0.125).tolist()[1:] + [2.98]\n",
    "mean_range = [-100, 100]\n",
    "sigma_range = [0.01, 40]\n",
    "n_range = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "\n",
    "\n",
    "data, y = generate_dataset(n_range, s_range, k_range, 100,\n",
    "                           mean_range=mean_range, sigma_range=sigma_range)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b63fad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f572cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = create_clf(q=0.2)\n",
    "clf.fit(data, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ce3312",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf['classifier'].loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f385e316",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a1ded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = [len(sample) for sample in data]\n",
    "ns = np.array(ns)\n",
    "y_pred = np.array(y_pred)\n",
    "for n in np.unique(ns):\n",
    "    mask = (ns == n)\n",
    "    print(n, np.round((np.equal(y[mask], y_pred[mask])).mean(), 4),\n",
    "         np.round((np.equal(y[mask & (y == 1)], y_pred[mask & (y == 1)])).mean(), 4),\n",
    "         np.round((np.equal(y[mask & (y == 0)], y_pred[mask & (y == 0)])).mean(), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc421b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = [len(sample) for sample in data]\n",
    "ns = np.array(ns)\n",
    "y_pred = np.array(y_pred)\n",
    "for n in np.unique(ns):\n",
    "    mask = (ns == n)\n",
    "    \n",
    "    print(n, np.round((np.equal(y[mask], y_pred[mask])).mean(), 4),\n",
    "         np.round((np.equal(y[mask & (y == 1)], y_pred[mask & (y == 1)])).mean(), 4),\n",
    "         np.round((np.equal(y[mask & (y == 0)], y_pred[mask & (y == 0)])).mean(), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc57d10e",
   "metadata": {},
   "source": [
    "### Test on New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee08340",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_range = [0] #NNm\n",
    "k_range = [1.02] + np.arange(1, 3, 0.125).tolist()[1:] + [2.98]\n",
    "mean_range1 = [1000, 2000]\n",
    "sigma_range1 = [100, 200]\n",
    "n_range1 = [15, 25, 35, 45, 55, 65, 75, 85, 95]\n",
    "\n",
    "\n",
    "test_data, y_test = generate_dataset(n_range, s_range, k_range, 100,\n",
    "                                     mean_range=mean_range1, sigma_range=sigma_range1)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d88e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = clf.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a1a47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_test = [len(sample) for sample in test_data]\n",
    "ns_test = np.array(ns_test)\n",
    "y_pred_test = np.array(y_pred_test)\n",
    "for n in np.unique(ns_test):\n",
    "    mask = (ns_test == n)\n",
    "    \n",
    "    print(n, np.round((np.equal(y_test[mask], y_pred_test[mask])).mean(), 4),\n",
    "         np.round((np.equal(y_test[mask & (y_test == 1)], y_pred_test[mask & (y_test == 1)])).mean(), 4),\n",
    "         np.round((np.equal(y_test[mask & (y_test == 0)], y_pred_test[mask & (y_test == 0)])).mean(), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57a3f91",
   "metadata": {},
   "source": [
    "### NDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b82c7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NDNNTest(object):\n",
    "    \"\"\"docstring for NDTNormality\"\"\"\n",
    "    def __init__(self, clf, alpha, m, rng, n_range, mean_range, sigma_range, n10=True, target_class=1, epsilon=0):\n",
    "        super(NDNNTest, self).__init__()\n",
    "        self.clf = clf\n",
    "        self.alpha = alpha\n",
    "        self.m = m\n",
    "        self.rng = rng\n",
    "        self.n_range = n_range\n",
    "        self.mean_range = mean_range\n",
    "        self.sigma_range = sigma_range\n",
    "        self.n10 = n10\n",
    "        self.target_class = target_class\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.clf.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.repeat(2, len(X))\n",
    "        X_scores = self.clf.predict_proba(X)[:, 1]\n",
    "        \n",
    "        if self.epsilon > 0:\n",
    "            lower_correction_bound = (1 - self.alpha) / self.m\n",
    "            upper_correction_bound = (self.epsilon * (self.m + 1) - self.alpha) / self.m\n",
    "\n",
    "        for (j, (score, sample)) in enumerate(zip(X_scores, X)):\n",
    "            mean = np.mean(sample)\n",
    "            sd = np.std(sample)\n",
    "            n = len(sample)\n",
    "            \n",
    "            mean_range = self.mean_range\n",
    "            sigma_range = self.sigma_range\n",
    "            \n",
    "            if self.n10 and n < 20:\n",
    "                n_range = [n]\n",
    "                m = self.m\n",
    "            else:\n",
    "                n_range = self.n_range\n",
    "                m = self.m // len(n_range)\n",
    "            \n",
    "            new_samples = util.generate_normal_samples(n_range, m,\n",
    "                                                       mean_range=self.mean_range,\n",
    "                                                      sigma_range=self.sigma_range)\n",
    "            scores = self.clf.predict_proba(new_samples)[:, 1]\n",
    "            \n",
    "            scores = np.sort(scores)\n",
    "            \n",
    "            more_extreme = np.searchsorted(scores, score, 'right')\n",
    "            \n",
    "            p_value = more_extreme / self.m\n",
    "        \n",
    "            if self.epsilon > 0:\n",
    "                correction = self.rng.uniform(lower_correction_bound, upper_correction_bound)\n",
    "                if p_value + correction <= self.alpha:\n",
    "                    predictions[j] = 1 - self.target_class\n",
    "                else:\n",
    "                    predictions[j] = self.target_class\n",
    "            else:\n",
    "                #r = st.norm.ppf(1 - 0.01 / 2) / (4*len(scores))\n",
    "                if p_value <= (self.alpha * (self.m + 1) - 1) / self.m:\n",
    "                    predictions[j] = 1 - self.target_class\n",
    "                else:\n",
    "                    predictions[j] = self.target_class\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f3ea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dbb5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndt = NDNNTest(clf, 0.05, 40, rng, n_range, mean_range, sigma_range, n10=False, target_class=1, epsilon=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1b8360",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_data = util.generate_normal_samples(n_range, 1000, mean_range=mean_range,\n",
    "                                          sigma_range=sigma_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c58c023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf8522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndt.alpha = 0.05\n",
    "ndt.m = 40\n",
    "ndt.n10=True\n",
    "start = time.time()\n",
    "y_ndt_pred = ndt.predict(normal_data)\n",
    "end = time.time()\n",
    "\n",
    "print(np.round(end - start, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d5a7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_ndt_pred == 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd1f3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_ndt_pred == 0).mean()\n",
    "ns_normal = [len(sample) for sample in normal_data]\n",
    "ns_normal = np.array(ns_normal)\n",
    "for n in np.unique(ns_normal):\n",
    "    mask = (ns_normal == n)\n",
    "    fn = (y_ndt_pred[mask] == 0).sum()\n",
    "    fnr = (y_ndt_pred[mask] == 0).mean()\n",
    "    l, u = proportion_confint(fn, 1000, 0.01, 'beta')\n",
    "    print(n, fnr, (np.round(l, 4), np.round(u, 4)))\n",
    "print((y_ndt_pred == 0).mean(),\n",
    "      proportion_confint((y_ndt_pred == 0).sum(), len(y_ndt_pred), 0.01, 'beta'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f4053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_ndt_pred == 0).mean()\n",
    "ns_normal = [len(sample) for sample in normal_data]\n",
    "ns_normal = np.array(ns_normal)\n",
    "for n in np.unique(ns_normal):\n",
    "    mask = (ns_normal == n)\n",
    "    fn = (y_ndt_pred[mask] == 0).sum()\n",
    "    fnr = (y_ndt_pred[mask] == 0).mean()\n",
    "    l, u = proportion_confint(fn, 1000, 0.01, 'beta')\n",
    "    print(n, fnr, (np.round(l, 4), np.round(u, 4)))\n",
    "print((y_ndt_pred == 0).mean(),\n",
    "      proportion_confint((y_ndt_pred == 0).sum(), len(y_ndt_pred), 0.01, 'beta'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd961146",
   "metadata": {},
   "source": [
    "### Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1d8413",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfd3d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.01, 0.05]\n",
    "test_names = ['SW', 'LF', 'AD', 'DP', 'JB', 'SF', 'CVM']\n",
    "tests = {\n",
    "    alpha : {} for alpha in alphas\n",
    "}\n",
    "for test_name in test_names:\n",
    "    test_function, test_statistic = util.get_test(test_name)\n",
    "    for alpha in alphas:\n",
    "        test = util.TestClassifier(test_function, test_statistic, alpha)\n",
    "        tests[alpha][test_name] = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d08e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KurtosisTest(object):\n",
    "    def __init__(self, alpha, alternative):\n",
    "        self.alpha = alpha\n",
    "        self.alternative = alternative\n",
    "    def predict(self, X):\n",
    "        return st.kurtosistest(X, axis=1, alternative=self.alternative).pvalue >= self.alpha\n",
    "    \n",
    "for alpha in alphas:\n",
    "    tests[alpha]['KT'] = KurtosisTest(alpha, 'less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c905389",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "#rng.normal(loc=0, scale=1, size=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cee35ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import normeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d088efb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 2000\n",
    "G_data = normeval.generate_G_data(n_range=n_range, L=L, groups = {4 : normeval.groups[4]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b540d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for alpha in alphas:\n",
    "    print(alpha)\n",
    "    ndt.alpha = alpha\n",
    "    ndt.m = int(2 / alpha)\n",
    "    ndt.n10 = True\n",
    "    new_power_results = normeval.evaluate_power(ndt, G_data)\n",
    "    new_power_results['alpha'] = alpha\n",
    "    new_power_results['test'] = 'NDTNT'\n",
    "    dfs.append(new_power_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa9759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_data[(4, 10)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0f2ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a427f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for alpha in tests:\n",
    "    print(alpha)\n",
    "    for code in tests[alpha]:\n",
    "        print('\\t', code)\n",
    "        test = tests[alpha][code]\n",
    "        df = normeval.evaluate_power(test, G_data)\n",
    "        df['alpha'] = alpha\n",
    "        df['test'] = code\n",
    "        dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ec2624",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_G = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12b0745",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_G = df_G.rename({4 : 'power'}, axis='columns')\n",
    "df_G = df_G.reset_index()\n",
    "df_G = df_G.rename({'index' : 'n'}, axis='columns')\n",
    "df_G['power'] = df_G['power'].astype(float)\n",
    "df_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc875901",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower, upper = proportion_confint(df_G['power'] * L, L, alpha=0.01, method='beta')\n",
    "df_G['lower'] = lower\n",
    "df_G['upper'] = upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d902e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_G = df_G.replace({'NDTNT' : 'NDT'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9571f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_spec = guide_legend(ncol=2)\n",
    "for alpha in alphas:\n",
    "    mask = (df_G['alpha'] == alpha) & (~df_G['test'].isin(['ZX', 'SF', 'JB']))\n",
    "    g = ggplot(df_G[mask], aes(x='n', y='power', color='test', shape='test')) +\\\n",
    "        geom_line(aes(group='test', linetype='test'), size=0.8) +\\\n",
    "        geom_ribbon(aes(fill='test', color='test', ymin='lower', ymax='upper'), alpha=0.1) +\\\n",
    "        geom_point(size=3) +\\\n",
    "        scale_color_brewer(type='qual', palette=2) +\\\n",
    "        scale_fill_brewer(type='qual', palette=2) +\\\n",
    "        scale_linetype_manual(['solid', 'dashed', 'dotted', 'dashdot',\n",
    "                               (0, (1, 2, 1, 1)), (0, (2,2,1,1)), (0, (5, 5))]) +\\\n",
    "        theme_classic() +\\\n",
    "        labs(x='$n$', y='Power') +\\\n",
    "        theme(legend_title=element_blank(),\n",
    "              legend_position=(0.26, 0.8),\n",
    "              legend_key_width=20, legend_box_margin=0) +\\\n",
    "        guides(fill=legend_spec, linetype=legend_spec, color=legend_spec, shape=legend_spec)\n",
    "    display(g)\n",
    "    filename = f'norm_ndt_power_comparison_alpha_{alpha}.jpg'\n",
    "    filename = os.path.join(ndt_res_dir, filename)\n",
    "    g.save(filename, dpi=500, width=5, height=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebff658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b0b0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(ndt_res_dir, 'clf.p')\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5af432",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d196e521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8405ad39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurips2022",
   "language": "python",
   "name": "neurips2022"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "215.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
